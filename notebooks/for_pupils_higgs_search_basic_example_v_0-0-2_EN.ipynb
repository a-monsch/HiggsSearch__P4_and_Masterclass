{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 0.0.2\n",
    "\n",
    "For the graphical application and the events for the Ispy-WebGL the for_masterclass.zip must be unpacked in the folder 'data'.\n",
    "The 'ig' files must be imported into the Ispy-WebGL after the mixing/splitting has been performed. The detailed information about the imported .ig files can be found under 'detailed_information'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the scope of this task, pupils are to have the opportunity to assign event images to certain decays and to make statements about the significance of having determined a certain excess of events by summarising the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T13:03:10.872949Z",
     "start_time": "2020-06-16T13:03:10.858156Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The event images used for this task have been taken from the [published data sets from 2011/2012](http://opendata.cern.ch/record/5500). In the 'data' folder there are exemplary events containing a decay into two Z-bosons and then four leptons.There are also decays into two photons or two W-bosons and then two leptons and two neutrinos. The non-$H\\rightarrow ZZ \\rightarrow 4\\ell$ decays are intended to show the different decay possibilities. For the subsequent summary of the events, only the decays in four leptons are used. The presentation is done using the [Ispy-webgl-Interface](http://ispy-webgl.web.cern.ch/ispy-webgl/)<sup>[1](https://iopscience.iop.org/article/10.1088/1742-6596/396/2/022022)</sup>.\n",
    "\n",
    "\n",
    "The task of the students is to find certain decays in the pre-selected events and to determine an invariant mass for the case of a decay into four leptons. \n",
    "The missing quantities such as the components of the individual four impulses can be determined by the students by applying the basics of vector calculus (see exemplary `get_energy_px_py_pz` below).\n",
    " With the help of these and other variables the students can determine the invariant mass using $$M_{\\mathrm{inv}}=\\sqrt{\\left( \\sum_i E_i \\right)^2 - \\left( \\sum_i \\vec{p}_i \\right)^2}\\, ,$$. The questions about the electric charges of the leptons decayed from the Z boson or the combination of leptons only from the same families can be taken from the additional information in the Ispy-webgl interface when looking at single selected particles.\n",
    "\n",
    "For the calculation of invariant masses or other quantities important to them, the students are free to create their own or use allready created functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T13:03:11.010999Z",
     "start_time": "2020-06-16T13:03:10.876148Z"
    }
   },
   "outputs": [],
   "source": [
    "# May be implemented by pupils\n",
    "import numpy as np\n",
    "\n",
    "def get_energy_px_py_pz(pt:list, eta:list, phi:list):\n",
    "    pt, eta, phi = np.array(pt), np.array(eta), np.array(phi)\n",
    "    # eta = -ln(tan(theta/2))\n",
    "    theta = 2 * np.arrayctan(np.exp(-eta))\n",
    "    p = pt / np.cos(np.pi / 2. - theta)\n",
    "    px, py, pz = pt * np.cos(phi), pt * np.sin(phi), np.sqrt(p ** 2 - pt ** 2)\n",
    "    # m << E\n",
    "    energy = p\n",
    "    return energy, px, py, pz\n",
    "    \n",
    "def invariant_mass_four_lepton(px: list, py: list, pz:list, energy=None):\n",
    "    px, py, pz= np.array(px), np.array(py), np.array(pz)\n",
    "    energy_sum = np.sum(energy) if energy is not None else np.sum(np.sqrt(px ** 2 + py ** 2 + pz ** 2))\n",
    "    return np.sqrt(energy_sum ** 2 - (np.sum(px) ** 2 + np.sum(py) ** 2 + np.sum(pz) ** 2))\n",
    "\n",
    "#..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\eta$ is the pseudorapidity, a spatial coordinate that specifies the angle between a vector and the beam axis and is converted back to the solid angle $\\theta$ in the above function. The beam axis points in the z direction. The transverse impulse lies in the x-y-plane and is described by its length and the azimuthal angle $\\phi$.\n",
    "\n",
    "For the calculation of the energy ($E^2 = m^2 + p^2 \\stackrel{p\\gg m}{\\approx} p^2$) the fact is used that the considered pulses (> 5 GeV) are significantly larger than the rest masses of the electrons (0.51 MeV) or muons (105.7 MeV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T13:03:11.016097Z",
     "start_time": "2020-06-16T13:03:11.013450Z"
    }
   },
   "outputs": [],
   "source": [
    "# possible calculations\n",
    "\n",
    "# my_pt = []\n",
    "# my_eta = []\n",
    "# my_phi = []\n",
    "\n",
    "# my_energy, my_px, my_py, my_pz = get_energy_px_py_pz(pt=my_pt, eta=my_eta, phi=my_phi)\n",
    "# my_mass = invariant_mass_four_lepton(px=my_px, py=my_py, pz=my_pz, energy=my_energy)\n",
    "# print(my_mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T13:03:11.029850Z",
     "start_time": "2020-06-16T13:03:11.018539Z"
    }
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<iframe src=\"https://ispy-webgl.web.cern.ch/ispy-webgl/\" width=\"100%\" height=\"700\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Students can then use the graphical application to compile the results into a histogram. If ipyparallel is not installed it is recommended to start the widget from a separate console to allow parallel working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T13:03:11.829309Z",
     "start_time": "2020-06-16T13:03:11.031968Z"
    }
   },
   "outputs": [],
   "source": [
    "from include.widget.HiggsWidget import WidgetHiggs as WH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T13:04:24.455211Z",
     "start_time": "2020-06-16T13:04:12.652016Z"
    }
   },
   "outputs": [],
   "source": [
    "def call_UI(my_function=None):\n",
    "    WH(b_num=37, hist_range=(70, 181), info=[[\"2012\"], [\"B\", \"C\"]],  # bins, range, records: [[\"year1\", \"year2\"], [\"run1\", \"run2\"]]\n",
    "       mc_dir_=\"../data/for_widgets/mc_aftH\",  # Folder with the underground simulations and the 125 GeV signal simulation\n",
    "       mc_other_dir=\"../data/for_widgets/other_mc/d---/mc_aftH\",  # Folder with further signal simulations\n",
    "       stat_eval_func=my_function # Statistical evaluation function, see below\n",
    "       )\n",
    "call_UI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under 'View - MC simulations on' the simulations of Higgs hypotheses for other Higgs masses can be viewed and under 'View - Signal MC scaling on' the simulations can be scaled accordingly.\n",
    "\n",
    "To evaluate which of the signal simulations is most appropriate, we want to determine (and implement) a pupil defined quantity that quantifies a difference between two hypotheses. In 'for_pupils_statistcs_basic_examples_v_0-0-1_EN' the significance value $p_0$, determined from $\\chi^2$, is presented for the evaluation of a hypothesis. Now two hypotheses are to be compared directly ($H_0$: only background (blue) or $H_{1, i}$: background and a signal hypothesis of mass $m_i$). The choice of this quantity can be freely chosen and can be adapted and changed by modifying the following function.\n",
    "\n",
    "Introduced is the relationship of two [likelihood functions](https://en.wikipedia.org/wiki/Likelihood_function). A likelihood function can be interpreted as an total probability to find the measurement $\\{X_1, X_2, ... X_n \\}$ under a known probability of the individual events in any order. To use the example from `for_pupils_statistcs_basic_examples_v_0-0-1_EN`: How probable is it to measure $\\{1,1,2,6,3\\}$ with an ideal dice?\n",
    "\n",
    "The answer (If the order is not important, an additional factor is added as the number of possible combinations, but this factor will be removed later when the ratio is formed): $$P_{\\mathrm{tot}} = \\prod_{X_i\\in \\{1,1,2,6,3\\}} P(X_i) = P(1)\\cdot P(1)\\cdot P(2)\\cdot P(6)\\cdot P(3) = \\frac{1}{6^5} \\, .$$\n",
    "The likelihood function can be defined as follows: $$\\mathcal{L} = \\prod_{X_i}^N P(X_i)\\, .$$ and is thus similar to $P_{\\mathrm{tot}}$. The probability of receiving individual events can also be expressed as a function if the events are no longer discrete but continuous. In this application only histograms are considered. For these $P(X_i)$ can be written as: $$ P(X_i) = \\frac{A_i^{X_i} }{X_i!} \\mathrm{e}^{-A_i} \\, $$ which corresponds to the Poisson statistics. $X_i$ is the number of measured events in a bin of the histogram, $A_i$ is the expected number of events in the respective bin. In the ratio of the two likelihood functions one is $A_i =A_{i,U}$ for the background only and $A_{i, U+S}$ which represents the background and a signal. To calculate the ratio numerically well the logarithm of the ratio is determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T13:03:24.175589Z",
     "start_time": "2020-06-16T13:03:24.166109Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exemplary code\n",
    "\n",
    "def statistical_evaluation(measurement,  # Measurement\n",
    "                           background_simulation,  # Simulation of the background\n",
    "                           signal_simulation,  # Simulation of the signal\n",
    "                           background_name=\"b\",  # Name of the background (optional)\n",
    "                           signal_name=\"s\"  # Name of the signal (optional)\n",
    "                           ):\n",
    "\n",
    "    # Logarithm of the likelihood function for background only\n",
    "    b_nll = sum(bac_s - m + m * np.log(m / bac_s) for (m, bac_s) in zip(measurement,\n",
    "                                                                        background_simulation) if float(m) != 0.0)\n",
    "    # Logarithm of the likelihood function for background and signal simulation\n",
    "    bs_nll = sum((bac_s + sig_s) - m + m * np.log(m / (bac_s + sig_s)) for (m, bac_s, sig_s) in zip(measurement, \n",
    "                                                                                                    background_simulation, \n",
    "                                                                                                    signal_simulation) if float(m) != 0.0)\n",
    "    \n",
    "    # Ratio of the two ln(L) functions. \n",
    "    # The factor 2 has been introduced for comparison with other sizes for the purpose of simplicity\n",
    "    nlr_ = 2 * (b_nll - bs_nll)\n",
    "    # we just want to detect a surplus of events. This will be a positive ratio:\n",
    "    q0_ = np.round(nlr_, 3) if nlr_ > 0 else 0\n",
    "    \n",
    "    # naming, optional\n",
    "    bn_, sn_ = background_name, signal_name\n",
    "    name_ = f\"$ 2 \\\\ln \\\\left( \\\\dfrac{{ \\\\mathcal{{L}}_{{ {bn_} + {sn_} }} }}{{ \\\\mathcal{{L}}_{{ {bn_} }} }}  \\\\right)$\"\n",
    "    \n",
    "    # The return value must be a tuple of the name (str) and the value (float/int)\n",
    "    return name_, q0_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The larger the value from the ratio of the two likelihood functions, the better the combination of signal and background fits rather than the background alone. The choice of a limit value at which the hypothesis $H_0$ is rejected is to a certain extent arbitrary. For a high value the probability of rejecting the null hypothesis $H_0$ although it is correct ([type I error](https://en.wikipedia.org/wiki/Type_I_and_type_II_errors#Definition)) is reduced but not excluded. The problem of confirming the null hypothesis although the alternative hypothesis is true ([type II error](https://en.wikipedia.org/wiki/Type_I_and_type_II_errors#Definition)) occurs when the signal strength cannot be distinguished from the natural fluctuations that always occur in such measurements.\n",
    "\n",
    "The signal distributions are created with the known theory. The deviation of the respective scaling from the factor 1 can also indicate that possible considerations in the theory are not completely covered. At the same time, the fluctuation of the measurement must be taken into account, which also results in a scaling of $\\mu$ - only integer events can be measured. The non-integer predictions result from scaling the simulation to the integrated luminosity of the measurement, similar to 'for_pupils_statistcs_basic_examples_v_0-0-1_EN'.\n",
    "\n",
    "\n",
    "Thus, the students should determine the most appropriate signal simulation taking into account the scaled signal distributions and the previously defined limit that the value must exceed the ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T13:03:33.483524Z",
     "start_time": "2020-06-16T13:03:24.195435Z"
    }
   },
   "outputs": [],
   "source": [
    "call_UI(my_function=statistical_evaluation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
