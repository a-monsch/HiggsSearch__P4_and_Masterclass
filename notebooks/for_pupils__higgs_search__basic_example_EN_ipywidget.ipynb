{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 0.0.2\n",
    "\n",
    "For the graphical application and the events for the Ispy-WebGL the for_masterclass.zip must be unpacked in the folder 'data'.\n",
    "The 'ig' files must be imported into the Ispy-WebGL after the mixing/splitting has been performed. The detailed information about the imported .ig files can be found under 'detailed_information'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the scope of this task, pupils are to have the opportunity to assign event images to certain decays and to make statements about the significance of having determined a certain excess of events by summarising the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The event images used for this task have been taken from the [published data sets from 2011/2012](http://opendata.cern.ch/record/5500). In the 'data' folder there are exemplary events containing a decay into two Z-bosons and then four leptons.There are also decays into two photons or two W-bosons and then two leptons and two neutrinos. The non-$H\\rightarrow ZZ \\rightarrow 4\\ell$ decays are intended to show the different decay possibilities. For the subsequent summary of the events, only the decays in four leptons are used. The presentation is done using the [Ispy-webgl-Interface](http://ispy-webgl.web.cern.ch/ispy-webgl/)<sup>[1](https://iopscience.iop.org/article/10.1088/1742-6596/396/2/022022)</sup>.\n",
    "\n",
    "\n",
    "The task of the students is to find certain decays in the pre-selected events and to determine an invariant mass for the case of a decay into four leptons. \n",
    "The missing quantities such as the components of the individual four impulses can be determined by the students by applying the basics of vector calculus (see exemplary `get_energy_px_py_pz` below).\n",
    " With the help of these and other variables the students can determine the invariant mass using $$M_{\\mathrm{inv}}=\\sqrt{\\left( \\sum_i E_i \\right)^2 - \\left( \\sum_i \\vec{p}_i \\right)^2}\\, ,$$ The questions about the electric charges of the leptons decayed from the Z boson or the combination of leptons only from the same families can be taken from the additional information in the Ispy-webgl interface when looking at single selected particles.\n",
    "\n",
    "For the calculation of invariant masses or other quantities important to them, the students are free to create their own or use allready created functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May be implemented by pupils\n",
    "import numpy as np\n",
    "\n",
    "def get_energy_px_py_pz(pt:list, eta:list, phi:list):\n",
    "    pt, eta, phi = np.array(pt), np.array(eta), np.array(phi)\n",
    "    # eta = -ln(tan(theta/2))\n",
    "    theta = 2 * np.arctan(np.exp(-eta))\n",
    "    p = pt / np.cos(np.pi / 2. - theta)\n",
    "    px, py, pz = pt * np.cos(phi), pt * np.sin(phi), np.sqrt(p ** 2 - pt ** 2)\n",
    "    # m << E\n",
    "    energy = p\n",
    "    return energy, px, py, pz\n",
    "    \n",
    "def invariant_mass_four_lepton(px: list, py: list, pz:list, energy=None):\n",
    "    px, py, pz= np.array(px), np.array(py), np.array(pz)\n",
    "    energy_sum = np.sum(energy) if energy is not None else np.sum(np.sqrt(px ** 2 + py ** 2 + pz ** 2))\n",
    "    return np.sqrt(energy_sum ** 2 - (np.sum(px) ** 2 + np.sum(py) ** 2 + np.sum(pz) ** 2))\n",
    "\n",
    "#..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\eta$ is the pseudorapidity, a spatial coordinate that specifies the angle between a vector and the beam axis and is converted back to the solid angle $\\theta$ in the above function. The beam axis points in the z direction. The transverse impulse lies in the x-y-plane and is described by its length and the azimuthal angle $\\phi$.\n",
    "\n",
    "For the calculation of the energy ($E^2 = m^2 + p^2 \\stackrel{p\\gg m}{\\approx} p^2$) the fact is used that the considered pulses (> 5 GeV) are significantly larger than the rest masses of the electrons (0.51 MeV) or muons (105.7 MeV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible calculations (example)\n",
    "\n",
    "# my_pt = [56.337,54.271,50.059,9.734]\n",
    "# my_eta = [-1.842,-0.848,-2.371,-2.206]\n",
    "# my_phi = [-0.144,0.851,0.497,-0.940]\n",
    "\n",
    "# my_energy, my_px, my_py, my_pz = get_energy_px_py_pz(pt=my_pt, eta=my_eta, phi=my_phi)\n",
    "# my_mass = invariant_mass_four_lepton(px=my_px, py=my_py, pz=my_pz, energy=my_energy)\n",
    "# print(my_mass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The display is done using the [IspyWebGL](https://zenodo.org/record/3886676) interface of the CMS detector. The events are loaded as follows: The desired IG files can be temporarily stored via the `Download` option in the `data/for_event_display_ig_files` folder and then read in via the `Open` IspyWebGL option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<iframe src=\"https://ispy-webgl.web.cern.ch/ispy-webgl/\" width=\"100%\" height=\"700\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Students can then use the graphical application to compile the results into a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from include.widget.HiggsWidget import HiggsWidget as HW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw = HW(language=\"DE\")\n",
    "hw.run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate which of the signal simulations is most appropriate, we want to determine (and implement) a pupil defined quantity that quantifies a difference between two hypotheses.In `for_pupils__statistcs_basic__dice_examples_EN_remote`, the significance value $p_0$, determined from chi-squared distribution ($\\chi^2$), is presented for the evaluation of a hypothesis.  Now two hypotheses are to be compared directly ($H_0$: only background (blue) or $H_{1, i}$: background and a signal hypothesis of mass $m_i$). The choice of this quantity can be freely chosen and can be adapted or changed by modifying the following function.\n",
    "\n",
    "The ratio of two [likelihood functions](https://en.wikipedia.org/wiki/Likelihood_function) is presented here. A likelihood function can be interpreted as an overall probability the measurement $\\{X_1, X_2, ... X_n \\}$ under a known probability of the individual events in any order. To use the example from `for_pupils__statistcs_basic__dice_examples_EN_remote`: How likely is it to measure $\\{1,1,2,6,3\\}$ with an ideal dice?\n",
    "\n",
    "The answer (if in addition the order is not important, there is an additional factor as the number of possible combinations, but this factor is later removed when the ratio is formed) is: $$P_{\\mathrm{tot}} = \\prod_{X_i\\in \\{1,1,2,6,3\\}} P(X_i) = P(1)\\cdot P(1)\\cdot P(2)\\cdot P(6)\\cdot P(3) = \\frac{1}{6^5} \\, .$$\n",
    "Where $\\prod$ describes the product between all $P(X_i)$ where the long variant $P(X_1) \\cdot P(X_2) \\cdot P(X_3) ... P(X_n)$ is shortened. The likelihood function can then be defined as follows: $$\\mathcal{L} = \\prod_{X_i}^N P(X_i)\\, ,$$ and is thus similar to $P_{\\mathrm{tot}}$. The probability of receiving individual events can also be expressed as a function if the events are no longer discrete but continuous. Only histograms are considered in the application. For these $P(X_i)$ can be written as: $$ P(X_i) = \\frac{A_i^{X_i} }{X_i!} \\mathrm{e}^{-A_i} \\, $$ which corresponds to the Poisson distribution. $X_i$ is the number of measured events in a bin of the histogram, $A_i$ is the expected number of events in the respective bin. \n",
    "A Poisson distribution is used whenever the frequency of rare events over a certain time is considered (in the limiting case of many events the Poisson distribution goes. against a normal distribution).\n",
    "\n",
    "In the ratio of the two likelihood functions one is $A_i =A_{i,U}$ for the background and $A_{i, U+S}$ which represents the background and a signal. To calculate the ratio numerically reliable the logarithm of the ratio is determined. It is then in detail:\n",
    "$$ \\ln \\left( \\frac{\\mathcal{L}_{U+S}}{\\mathcal{L}_U} \\right)  = \\ln \\left( {\\mathcal{L}_{U+S}} \\right) - \\ln \\left( {\\mathcal{L}_{U}} \\right) = \\left( \\sum_{i=0}^N X_i \\ln \\left( A_{i, U+S} \\right) - A_{i, U+S} \\right) - \\left( \\sum_{i=0}^N X_i \\ln \\left( A_{i, U} \\right) - A_{i, U} \\right) = \\sum_{i=0}^N X_i \\ln \\left( \\frac{A_{i,U+S}}{A_{i,U}}  \\right) - \\left(A_{i,U+S} -A_{i,U}  \\right) \\, .$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplary code\n",
    "\n",
    "def statistical_evaluation(measurement,  # Measurement\n",
    "                           background_simulation,  # Simulation of the background\n",
    "                           signal_simulation,  # Simulation of the signal\n",
    "                           background_name=\"b\",  # Name of the background (optional)\n",
    "                           signal_name=\"s\"  # Name of the signal (optional)\n",
    "                           ):\n",
    "\n",
    "    # Logarithm of the likelihood function for background only\n",
    "    b_nll = sum(bac_s - m + m * np.log(m / bac_s) for (m, bac_s) in zip(measurement,\n",
    "                                                                        background_simulation) if float(m) != 0.0)\n",
    "    # Logarithm of the likelihood function for background and signal simulation\n",
    "    bs_nll = sum((bac_s + sig_s) - m + m * np.log(m / (bac_s + sig_s)) for (m, bac_s, sig_s) in zip(measurement, \n",
    "                                                                                                    background_simulation, \n",
    "                                                                                                    signal_simulation) if float(m) != 0.0)\n",
    "    \n",
    "    # Ratio of the two ln(L) functions. \n",
    "    # The factor 2 has been introduced for comparison with other sizes for the purpose of simplicity\n",
    "    nlr_ = 2 * (b_nll - bs_nll)\n",
    "    # we just want to detect a surplus of events. This will be a positive ratio:\n",
    "    q0_ = np.round(nlr_, 3) if nlr_ > 0 else 0\n",
    "    \n",
    "    # naming, optional\n",
    "    bn_, sn_ = background_name, signal_name\n",
    "    name_ = f\"$ 2 \\\\ln \\\\left( \\\\dfrac{{ \\\\mathcal{{L}}_{{ {bn_} + {sn_} }} }}{{ \\\\mathcal{{L}}_{{ {bn_} }} }}  \\\\right)$\"\n",
    "    \n",
    "    # The return value must be a tuple of the name (str) and the value (float/int)\n",
    "    return name_, q0_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The larger the value from the ratio of the two likelihood functions, the better the combination of signal and background fits rather than the background alone. The choice of a limit value at which the hypothesis $H_0$ is rejected is to a certain extent arbitrary. For a high value the probability of rejecting the null hypothesis $H_0$ although it is correct ([type I error](https://en.wikipedia.org/wiki/Type_I_and_type_II_errors#Definition)) is reduced but not excluded. The problem of confirming the null hypothesis although the alternative hypothesis is true ([type II error](https://en.wikipedia.org/wiki/Type_I_and_type_II_errors#Definition)) occurs when the signal strength cannot be distinguished from the natural fluctuations that always occur in such measurements.\n",
    "\n",
    "The motivation behind considering the ratio of the two likelihoods is that even for a very small number of events (as is the case in this example) an analytical form can be found to describe the $p$ value (the exact derivation is not so important at this point) and no elaborate additional considerations are necessary. The $p$ value that can be determined in this way can easily be converted into a value for significance: This is just the root of the ratio.\n",
    "\n",
    "$N \\cdot \\sigma$ thus corresponds to the area under the tail of a Gaussian distribution, starting at $N \\cdot \\sigma$ far away from the mean and corresponds to the probability ($p$ value, see notebook on statistical basics) that the observed measurement is purely random. In other sciences the typical $p$ value is $0.05$ which corresponds to about $1.96 \\sigma$. In experimental particle physics, on the other hand, the $3\\sigma$ limit has to be exceeded for an indication ($p=2.7 \\cdot 10^{-3}$). A discovery in experimental particle physics is called if the value is greater than $5\\sigma$ ($p=5.7 \\cdot 10^{-7}$). With the measurements provided for this experiment the pupils can determine the indication of a Higgs boson in the four lepton decay channel.\n",
    "\n",
    "The signal distributions are created with the known theory. The deviation of the respective scaling from the factor 1 can also indicate that possible considerations in the theory are not completely covered. At the same time, the fluctuation of the measurement must be taken into account, which also results in a scaling of $\\mu$ - only integer events can be measured. The non-integer predictions result from scaling the simulation to the integrated luminosity of the measurement, similar to `for_pupils__statistcs_basic__dice_examples_EN_remote`.\n",
    "\n",
    "\n",
    "Thus, the students should determine the most appropriate signal simulation taking into account the scaled signal distributions and the previously defined limit that the value must exceed the ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw.stat_eval_func = statistical_evaluation\n",
    "hw.run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
